{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c78514-e321-47d4-a604-bc523d028af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3479d577-191e-47a1-92ba-6769f86a5e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load and preprocess the data\n",
    "data = []  # List to store image data\n",
    "labels = []  # List to store labels\n",
    "\n",
    "# Define a function to extract the person label from the file name\n",
    "def extract_person_label(file_name):\n",
    "    return int(file_name.split('.')[0].replace('subject', '')) - 1  # Subtract 1 to make labels start from 0\n",
    "\n",
    "# Load data and labels\n",
    "# Assuming the dataset files are in the 'dataset' directory\n",
    "dataset_dir = 'E:/Desktop/DL_codes/yale'\n",
    "\n",
    "for file_name in os.listdir(dataset_dir):\n",
    "    img = plt.imread(os.path.join(dataset_dir, file_name))\n",
    "    #print(img.shape) 243*320\n",
    "    data.append(img.flatten())  # Flatten image into a 1D array\n",
    "    labels.append(extract_person_label(file_name))\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "len(X_train),len(y_train)\n",
    "\n",
    "import random\n",
    "\n",
    "# Randomly select four indices from the training dataset\n",
    "train_indices = random.sample(range(len(X_train)), 4)\n",
    "\n",
    "# Randomly select four indices from the testing dataset\n",
    "test_indices = random.sample(range(len(X_test)), 4)\n",
    "\n",
    "# Function to display images\n",
    "def display_images(images, labels, title):\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.suptitle(title)\n",
    "    for i, (image, label) in enumerate(zip(images, labels), 1):\n",
    "        plt.subplot(1, 4, i)\n",
    "        plt.imshow(image.reshape((243, 320)), cmap='gray')\n",
    "        plt.title(f\"Person {label}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display four random training images\n",
    "train_images_to_display = X_train[train_indices]\n",
    "train_labels_to_display = y_train[train_indices]\n",
    "display_images(train_images_to_display, train_labels_to_display, \"Random Training Images\")\n",
    "\n",
    "# Display four random testing images\n",
    "test_images_to_display = X_test[test_indices]\n",
    "test_labels_to_display = y_test[test_indices]\n",
    "display_images(test_images_to_display, test_labels_to_display, \"Random Testing Images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff83ceb-0872-421b-b0cc-b5c39ca69498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MLP classifier instance\n",
    "mlp = MLPClassifier(max_iter=100)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (100, 50), (100, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_mlp = MLPClassifier(max_iter=100, **best_params)\n",
    "\n",
    "best_mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babd17e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
